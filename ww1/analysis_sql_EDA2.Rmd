---
title: "Untitled"
output: html_document
---


```{r}
# install.packages(c('ggplot2', 'tidyr', 'ROCR', 'broom', 'readr',    
#                    'dplyr', 'DBI', 'RSQLite',
#                    'tibble', 'lattice', 'modelr', 'stringr', 'MASS', 
#                    'car',
#                    'caret', 'gridExtra', 'lsmeans', 'lme4'))

library(ggplot2)
#library(plotly)
library(dplyr)
library(tibble)
library(readr) # str_c, str_sub
library(tidyr)
library(broom) # tidy(model)
library(stringr)
library(modelr) # add_residuals
library(lattice) # splom
library(gridExtra) # grid.arrange
library(MASS) # for lm.ridge and boxcox, also fucks up dplyrs select 
library(car) # for vif
library(lsmeans) # for adjusted means
library(caret) # confusionMatrix
library(ROCR)
library(lme4) 


```


- derive associatiations
- use to esdtablish a graph
- then look for communities in that graph? / clusters?
    - notice the betweenness centrality based community detection would work well bc we can remove the people who are overlapping and be left w the communities 
    - think of a grocery store, various cuisines and then people who eat lots of different cuisines are screwing up your results
    
    
- knitting across different languages: 
    - (http://rmarkdown.rstudio.com/authoring_knitr_engines.html?utm_content=buffer5cc17&utm_medium=social&utm_source=twitter.com&utm_campaign=buffer)
- data: https://blogs.technet.microsoft.com/dataplatforminsider/2016/06/09/wideworldimporters-the-new-sql-server-sample-database/
- ex: https://github.com/Microsoft/sql-server-samples/blob/master/samples/databases/wide-world-importers/sample-scripts/operational-analytics/DemonstrateOperationalAnalyticsPerformance.sql


# Goals
- unsupervised:
    - identify associations between products
    - rep products as a graph
    - get an idea for the similar products by grouping them
- supervised ideas:
    - forecast sales 
    - forecast whether sales persons sales are going to increase or decrease from 1 time period to the next (yearly)
    - recommend products based on associations
    - predict when we'll be undersupplied
    
- use:
    - cross reference w Customer Categories

```{r, max.print=5}
library(RODBC) 
#db <- odbcDriverConnect('driver={SQL Server};server=localhost;database=WideWorldImporters;trusted_connection=true')
drv <- odbcDriverConnect('driver={SQL Server};server=THE-ENTERPRISE\\SQLEXPRESS;database=WideWorldImporters;trusted_connection=true')
sqlQuery(drv, 'select * from information_schema.tables')
```



## little exploration in sql
- lets decide what we want to use as features and get a better look into our data
```{r}
sqlQuery(drv, 'select top 10 * from Sales.OrderLines;') # products
sqlQuery(drv, 'select top 10 * from Sales.Orders;') # orders
sqlQuery(drv, 'select top 10 * from [Application].[People];', rows_at_time = 1, max=10) # info on sales people not helpful
# cant allocate enough memoria
# couldnt allocate enough memory in R
sqlQuery(drv, 'select min(OrderDate) from Sales.Orders;')
sqlQuery(drv, 'select max(OrderDate) from Sales.Orders;')
sqlQuery(drv, 'select count(*)  from Sales.OrderLines;') 
sqlQuery(drv, 'select count(*) from Sales.Orders;')
# lets look for more features
sqlQuery(drv, 'select top 10 * from Sales.BuyingGroups;') # not helpful
# could look into more, look for an effect
sqlQuery(drv, 'select top 10 * from Sales.SpecialDeals;') # not helpful
# deals could have been confounding results on us
sqlQuery(drv, 'select top 10 * from Sales.Customers;', rows_at_time = 1, max=10) # helpful w below
sqlQuery(drv, 'select top 10 * from Sales.CustomerCategories;') # helpful
sqlQuery(drv, 'select count(*) from Sales.CustomerCategories_Archive;') # not helpful
# get geographic data
sqlQuery(drv, 'select top 10 
                	t3.CustomerName, t6.CityName, t7.StateProvinceName,
                	t8.CountryName
                from Sales.Customers as t3
                	inner join Application.Cities as t6
                		on t3.DeliveryCityID = t6.CityID
                	inner join Application.StateProvinces as t7
                		on t7.StateProvinceID = t6.StateProvinceID
                	inner join Application.Countries as t8
                		on t7.CountryID = t8.CountryID;')
```


## lets try to identify what drives the most revenue per order, while controlling for as much bias as possible
- confounding variables are a huge concern
- 

### train test split
- should always do so
- train test eval set is even better
- **if we were making a model for prediction more than inference we should have kept a hold out set into the future (last few months)**

```{r}
train <- tbl_df(sqlQuery(drv, 'select * from feature_table_train;'))
```


### EDA (R is the best for EDA)
- see chapter 7 of R4DS by hadley wickham: http://r4ds.had.co.nz/exploratory-data-analysis.html


#### dependent variable

```{r}
ggplot(train, aes(order_rev)) + 
  geom_histogram()
```

- to make this easier to work with lets log this 
    - extreme outliers will make it harder to interpret our results visually
    - and worsen our results from linea regression
    
```{r}
print(min(train$order_rev))
train <- train %>% mutate(log_rev = log(order_rev))

ggplot(train, aes(log_rev)) + geom_histogram()
```


#### how much variability do we have between months and years?

```{r}
ggplot(train, aes(as.factor(order_year), log_rev)) + 
  geom_boxplot()

ggplot(train, aes(as.factor(order_month), log_rev)) + 
  geom_boxplot()
```

#### what if we isolate to individual sales persons and customer categories

```{r}
ggplot(train, aes(as.factor(order_year), log_rev, fill=as.factor(SalespersonPersonID))) + 
  geom_boxplot()

ggplot(train, aes(as.factor(order_year), log_rev, fill=as.factor(CustomerCategoryID))) + 
  geom_boxplot()
```

- more variability, than before as we would expect

#### do we have enough data to narrow down into subcategries?
- if not we'll end up overfitting and our insights wont be valid

```{r}
train %>% group_by(order_month, SalespersonPersonID) %>% count() %>% arrange(n)
train %>% group_by(order_month, CustomerCategoryID) %>% count()  %>% arrange(n)
train %>% group_by(order_month, StateProvinceID) %>% count()  %>% arrange(n)
```

- state/province is more concentrated than the others
    - if we were to include the interaction w this and each month we'd want to filter out the less common states

#### lets look at the other on a weekly level

```{r}
train %>% group_by(order_wk, SalespersonPersonID) %>% count() %>% arrange(n)
train %>% group_by(order_wk, CustomerCategoryID) %>% count()  %>% arrange(n)
```

not bad, but still quite small


### linear model

```{r}
lm1 <- lm(log_rev ~ as.factor(order_month) + as.factor(order_year) + as.factor(order_wk) +
           as.factor(SalespersonPersonID) + as.factor(CustomerCategoryID) + as.factor(StateProvinceID),
         data=train)

anova(lm1)
```

```{r}
ggplot(train, aes(as.factor(order_wk), log_rev)) + geom_boxplot()
```

lets look a little deeper for seasonal trends for each feature

```{r}
lm1 <- lm(log_rev ~ as.factor(order_year) *  as.factor(SalespersonPersonID) +
            as.factor(order_month) * as.factor(SalespersonPersonID) +
            as.factor(order_year) *  as.factor(CustomerCategoryID) +
            as.factor(order_month) * as.factor(CustomerCategoryID) +
            as.factor(order_wk) + 
          + as.factor(StateProvinceID),
         data=train)

anova(lm1)
```

```{r}
par(mfrow=c(2,2))
plot(lm1)
```



#### still very little effects from our features


## potentially too many outliers to interpret effects with our features, we can fix this by binarizing our dependent

```{r}

train <- train %>% mutate(y = order_rev > 5000)

ggplot(train, aes(as.factor(order_year), fill=as.factor(y))) + 
  geom_bar(position='dodge')
ggplot(train, aes(as.factor(CustomerCategoryName), fill=as.factor(y))) + 
  geom_bar(position='dodge')
ggplot(train, aes(as.factor(SalespersonPersonID), fill=as.factor(y))) + 
  geom_bar(position='dodge')
```



```{r}
library(MASS)

glm1 <- glm(y ~ as.factor(order_year) +  as.factor(SalespersonPersonID) +
            as.factor(order_month)  + as.factor(CustomerCategoryID) +
            as.factor(order_wk) + 
          + as.factor(StateProvinceID),
         data=train, family='binomial')

anova(glm1, test='LRT')
```

